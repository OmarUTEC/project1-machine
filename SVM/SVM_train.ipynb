{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODELO SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando las bibliotecas necesarias\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import SVM as svmf\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creacion de clase SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clase SVM (Support Vector Machine) para clasificación multiclase\n",
    "\n",
    "class SVM:\n",
    "    def __init__(self, C, epochs, alpha):\n",
    "        # Inicializa los hiperparámetros del modelo SVM\n",
    "        self.C = C            # Parámetro de regularización\n",
    "        self.epochs = epochs  # Número de épocas de entrenamiento\n",
    "        self.alpha = alpha    # Tasa de aprendizaje\n",
    "\n",
    "    def fit(self, x, y):\n",
    "        # Ajusta el modelo SVM a los datos de entrenamiento\n",
    "        self.classes = np.unique(y)  # Encuentra las clases únicas en las etiquetas\n",
    "        self.classifiers = {}        # Almacena los clasificadores para cada clase\n",
    "\n",
    "        for class_label in self.classes:\n",
    "            # Convierte las etiquetas en un problema binario (+1 para la clase actual, -1 para las demás)\n",
    "            y_binary = np.where(y == class_label, 1, -1)\n",
    "            # Entrena el clasificador para la clase actual\n",
    "            classification = self.train(x, y_binary)\n",
    "            self.classifiers[class_label] = classification\n",
    "\n",
    "    def train(self, x, y):\n",
    "        # Entrenamiento del clasificador SVM para una clase específica\n",
    "        num_samples, num_features = x.shape\n",
    "        w = np.zeros(num_features)  # Inicializa los pesos\n",
    "        bias = 0                   # Inicializa el sesgo (bias)\n",
    "\n",
    "        for epoch in range(self.epochs):\n",
    "            for i in range(num_samples):\n",
    "                # Calcula la condición hinge loss para la muestra actual\n",
    "                condition = y[i] * (np.dot(x[i], w) - bias) >= 1\n",
    "                if condition:\n",
    "                    # Actualiza los pesos si se cumple la condición (clase bien clasificada)\n",
    "                    w -= self.alpha * (2 * self.C * w)\n",
    "                else:\n",
    "                    # Actualiza los pesos y el sesgo si no se cumple la condición (clase mal clasificada)\n",
    "                    w -= self.alpha * (2 * self.C * w - np.dot(x[i], y[i]))\n",
    "                    bias -= self.alpha * y[i]\n",
    "\n",
    "        return w, bias\n",
    "\n",
    "    def predict(self, x):\n",
    "        # Realiza predicciones para un conjunto de datos de entrada\n",
    "        predictions = []\n",
    "\n",
    "        for i in range(x.shape[0]):\n",
    "            scores = {}\n",
    "            for class_label, classifier in self.classifiers.items():\n",
    "                # Calcula la puntuación para cada clase utilizando el clasificador correspondiente\n",
    "                weights, bias = classifier\n",
    "                score = np.dot(x[i], weights) - bias\n",
    "                scores[class_label] = score\n",
    "\n",
    "            # Elige la clase con la puntuación más alta como la predicción\n",
    "            predicted_class = max(scores, key=scores.get)\n",
    "            predictions.append(predicted_class)\n",
    "\n",
    "        return np.array(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para calcular la pérdida del SVM (Hinge loss + Regularización)\n",
    "def loss(y, x, w, bias, c):\n",
    "    hinge_loss = c * np.sum(np.maximum(0, 1 - y * (np.dot(x, w) + bias)))\n",
    "    regularization_term = np.dot(w, w) / 2\n",
    "    return hinge_loss + regularization_term\n",
    "\n",
    "# Función para calcular el gradiente de la pérdida del SVM\n",
    "def grad(y, x, w, bias, c):\n",
    "    gradient = []\n",
    "    if y * (np.dot(x, w) + bias) >= 1:\n",
    "        gradient.append(w)\n",
    "        gradient.append(0)\n",
    "    else:\n",
    "        gradient.append(w - c * x * y)\n",
    "        gradient.append(-c * y)\n",
    "    return gradient\n",
    "\n",
    "# Función para actualizar los pesos y el sesgo con el gradiente y la tasa de aprendizaje\n",
    "def update(w, b, gradient, alpha):\n",
    "    w -= alpha * gradient[0]\n",
    "    b -= alpha * gradient[1]\n",
    "    return w, b\n",
    "\n",
    "# Función hallar la presicion de nuestro modelo una vez entrenado\n",
    "def accuracy(y_prueba,y_correct):\n",
    "    correctos= np.sum(y_prueba == y_correct)\n",
    "    return (correctos/len(y_correct))*100      \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión entrenamiento:  32.0\n",
      "Precisión testeo:  38.4\n"
     ]
    }
   ],
   "source": [
    "# Cargando el conjunto de datos de mariposas\n",
    "data_mariposas = pd.read_csv('../Vectores_Caracteristicos_Mariposas.csv')\n",
    "\n",
    "# Dividiendo el conjunto de datos en características (X) y etiquetas (y)\n",
    "X_mariposas = data_mariposas.drop('Etiqueta', axis=1).values\n",
    "y_mariposas = data_mariposas['Etiqueta'].values\n",
    "\n",
    "\n",
    "# Divide los datos de entrenamiento (70%) y conjunto temporal (30%)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X_mariposas, y_mariposas, test_size=0.3, random_state=42)\n",
    "\n",
    "# Divide el conjunto temporal en validación (15%) y prueba (15%)\n",
    "X_validation, X_test_mariposas, y_validation, y_test_mariposas = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Normalizar los datos\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_validation = scaler.transform(X_validation)\n",
    "X_test_mariposas = scaler.transform(X_test_mariposas)\n",
    "\n",
    "\n",
    "modelo = SVM(1,400,0.0001)\n",
    "modelo.fit(X_train, y_train)\n",
    "\n",
    "# Validación\n",
    "y_pred_val = modelo.predict(X_validation)\n",
    "precision_val=accuracy(y_validation,y_pred_val)\n",
    "\n",
    "print(\"Precisión entrenamiento: \", precision_val)\n",
    "\n",
    "# Predicción\n",
    "y_pred_test = modelo.predict(X_test_mariposas)\n",
    "precision_test=accuracy(y_test_mariposas,y_pred_test)\n",
    "\n",
    "print(\"Precisión testeo: \",precision_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
